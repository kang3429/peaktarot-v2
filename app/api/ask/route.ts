import { NextResponse } from "next/server";

export async function POST(req: Request) {
  const { question } = await req.json();
  const apiKey = process.env.OPENAI_API_KEY;

  console.log("ğŸ”‘ API Key:", apiKey); // í™˜ê²½ë³€ìˆ˜ í™•ì¸ìš©

  const prompt = `ì‚¬ìš©ìê°€ íƒ€ë¡œ ì ì„ ë´…ë‹ˆë‹¤. ì§ˆë¬¸: "${question}"\níƒ€ë¡œ ë¦¬ë”©ì²˜ëŸ¼ ì‹ ë¹„ë¡­ê³  ì‹ ì¤‘í•œ ë§íˆ¬ë¡œ ì§ê´€ì ì¸ í•´ì„ì„ í•´ì£¼ì„¸ìš”.`;

  try {
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content: "ë‹¹ì‹ ì€ ì‹ ë¹„ë¡œìš´ íƒ€ë¡œ ë§ˆìŠ¤í„°ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì‹ ì¤‘í•˜ê³  ì‹ ë¹„í•œ ì–´ì¡°ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.",
          },
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: 0.85,
      }),
    });

    const data = await res.json();

    console.log("ğŸ§  GPT ì‘ë‹µ:", data); // ì‘ë‹µ í™•ì¸

    const answer = data.choices?.[0]?.message?.content || "ë¦¬ë”©ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”.";
    return NextResponse.json({ answer });
  } catch (error) {
    console.error("âŒ GPT í˜¸ì¶œ ì¤‘ ì—ëŸ¬:", error);
    return NextResponse.json({ answer: "âš ï¸ ë¦¬ë”©ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”." }, { status: 500 });
  }
}
